# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qXR6LNquSUe_pPANkMkEKDBSyqQ0Zxhm
"""

import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, MinMaxScaler

# 1. Cargar dataset
df = pd.read_excel("Actividad 1. dataset_vivero.xlsx")

print("Datos originales:")
print(df.head())

# 2. Detección de problemas
print("\nValores nulos por columna:")
print(df.isnull().sum())

# 3. Imputación de datos numéricos (media o mediana)
num_cols = df.select_dtypes(include=['float64', 'int64']).columns
imputer_media = SimpleImputer(strategy='median')
df[num_cols] = imputer_media.fit_transform(df[num_cols])

# 4. Imputación de datos categóricos (moda)
cat_cols = df.select_dtypes(include=['object']).columns
imputer_moda = SimpleImputer(strategy='most_frequent')
df[cat_cols] = imputer_moda.fit_transform(df[cat_cols])

# 5. Codificación One-Hot de variables categóricas
cat_cols_for_encoding = [col for col in cat_cols if col != 'PlantaID']
encoder = OneHotEncoder(drop='first', sparse_output=False)
encoded_cols = pd.DataFrame(encoder.fit_transform(df[cat_cols_for_encoding]), columns=encoder.get_feature_names_out(cat_cols_for_encoding))
df = df.drop(cat_cols_for_encoding, axis=1)
df = pd.concat([df, encoded_cols], axis=1)

# 6. Escalamiento MinMax de las variables numéricas
num_cols = df.select_dtypes(include=['float64', 'int64']).columns
scaler = MinMaxScaler()
df[num_cols] = scaler.fit_transform(df[num_cols])

# 7. Mostrar datos transformados
print("\nDatos transformados:")
print(df.head())

# Guardar dataset limpio
df.to_excel("Dataset_Vivero_Transformado.xlsx", index=False)
print("\nArchivo 'Dataset_Vivero_Transformado.xlsx' generado correctamente.")
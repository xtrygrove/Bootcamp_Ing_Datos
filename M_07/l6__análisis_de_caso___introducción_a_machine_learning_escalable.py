# -*- coding: utf-8 -*-
"""L6 |Análisis de caso | Introducción a machine learning escalable.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qyfyr_B0kNZxQrCO2yKPXwXo4OA7tadJ
"""

!apt-get -q install openjdk-11-jdk-headless -y >/dev/null
!pip -q install pyspark==3.5.1 findspark >/dev/null

import os, findspark
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-11-openjdk-amd64"
findspark.init()
import pyspark
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("MLlib-Prod-Pipeline") \
    .config("spark.ui.showConsoleProgress","false") \
    .getOrCreate()

spark.version

from pyspark.sql import functions as F
from pyspark.sql.types import *


# Dataset sintético reproducible
data = [
 (25, "M",  3,  120.5, "mobile", 1),
 (33, "F",  1,   40.0,  "desktop",0),
 (41, "F",  8,  560.2, "mobile", 1),
 (29, "M",  2,   75.0,  "tablet", 0),
 (38, "M", 10,  820.9, "mobile", 1),
 (22, "F",  0,   10.0,  "desktop",0),
 (47, "F",  6,  310.1, "tablet", 1),
 (53, "M",  5,  240.0, "mobile", 0),
 (36, "F",  4,  155.5, "desktop",1),
 (30, "M",  3,  130.0, "mobile", 0),
]
schema = StructType([
    StructField("edad", IntegerType()),
    StructField("genero", StringType()),
    StructField("frecuencia", IntegerType()),
    StructField("monto_total", DoubleType()),
    StructField("dispositivo", StringType()),
    StructField("label", IntegerType())
])
df = spark.createDataFrame(data, schema)
df.show(5, False); df.printSchema()

from pyspark.sql import functions as F

# ejemplo: cap outliers simples (opcional)
num_cols = ["edad","frecuencia","monto_total"]
for c in num_cols:
    q1, q3 = df.approxQuantile(c, [0.25, 0.75], 0.05)
    iqr = q3 - q1
    lo, hi = q1 - 1.5*iqr, q3 + 1.5*iqr
    df = df.withColumn(c, F.when((F.col(c)<lo)|(F.col(c)>hi), F.lit(q3)).otherwise(F.col(c)))

train, test = df.randomSplit([0.7,0.3], seed=42)
train.count(), test.count()

from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Imputer
from pyspark.ml import Pipeline

cat_cols = ["genero","dispositivo"]
num_cols = ["edad","frecuencia","monto_total"]

indexers = [StringIndexer(inputCol=c, outputCol=f"{c}_idx", handleInvalid="keep") for c in cat_cols]
ohe = OneHotEncoder(inputCols=[f"{c}_idx" for c in cat_cols],
                    outputCols=[f"{c}_ohe" for c in cat_cols])
imputer = Imputer(inputCols=num_cols, outputCols=[f"{c}_imputed" for c in num_cols])

feature_cols = [f"{c}_imputed" for c in num_cols] + [f"{c}_ohe" for c in cat_cols]
assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")

base_stages = indexers + [ohe, imputer, assembler]

from pyspark.ml.classification import LogisticRegression, RandomForestClassifier
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.ml.evaluation import BinaryClassificationEvaluator

lr = LogisticRegression(featuresCol="features", labelCol="label", maxIter=50)
rf = RandomForestClassifier(featuresCol="features", labelCol="label", numTrees=80, maxDepth=6)

# Elige modelo aquí:
model_choice = "rf"  # "lr" o "rf"
clf = rf if model_choice=="rf" else lr

pipeline = Pipeline(stages=base_stages + [clf])

# Grilla simple
if model_choice=="rf":
    grid = (ParamGridBuilder()
            .addGrid(rf.numTrees, [50, 100])
            .addGrid(rf.maxDepth, [5, 8])
            .build())
else:
    grid = (ParamGridBuilder()
            .addGrid(lr.regParam, [0.0, 0.01, 0.1])
            .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])
            .build())

evaluator = BinaryClassificationEvaluator(labelCol="label", rawPredictionCol="rawPrediction", metricName="areaUnderROC")

cv = CrossValidator(estimator=pipeline,
                    estimatorParamMaps=grid,
                    evaluator=evaluator,
                    numFolds=3,
                    parallelism=2,
                    seed=42)

cv_model = cv.fit(train)
pred = cv_model.transform(test)
auc = evaluator.evaluate(pred)
print(f"AUC(ROC): {auc:.4f}")
pred.select("features","label","probability","prediction").show(10, False)

from pyspark.ml.evaluation import MulticlassClassificationEvaluator

# F1 / Precision / Recall
e_f1  = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="f1")
e_pr  = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="precisionByLabel")
e_rc  = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="recallByLabel")
f1, prec_pos, rec_pos = e_f1.evaluate(pred), e_pr.evaluate(pred), e_rc.evaluate(pred)

# PR AUC
pr_eval = BinaryClassificationEvaluator(labelCol="label", rawPredictionCol="rawPrediction", metricName="areaUnderPR")
pr_auc = pr_eval.evaluate(pred)

print(f"F1: {f1:.4f} | Precision(+): {prec_pos:.4f} | Recall(+): {rec_pos:.4f} | PR AUC: {pr_auc:.4f}")

# Matriz de confusión
cm = (pred.groupBy("label","prediction").count()
          .orderBy("label","prediction"))
cm.show()

save_path = "/content/mllib_best_model"
# limpia si existe
import shutil, os
if os.path.exists(save_path): shutil.rmtree(save_path)

cv_model.bestModel.write().overwrite().save(save_path)
print("Modelo guardado en:", save_path)

# ejemplo de carga
from pyspark.ml.pipeline import PipelineModel
loaded = PipelineModel.load(save_path)
_ = loaded.transform(test).select("prediction").show(3)

(pred.select("label","prediction","probability")
     .toPandas()
     .to_csv("/content/predicciones.csv", index=False))
"/content/predicciones.csv"